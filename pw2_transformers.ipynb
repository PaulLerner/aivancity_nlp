{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PaulLerner/aivancity_nlp/blob/main/pw2_transformers.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and imports\n",
    "\n",
    "Hit `Ctrl+S` to save a copy of the Colab notebook to your drive\n",
    "\n",
    "Run on Google Colab GPU:\n",
    "- Connect\n",
    "- Modify execution\n",
    "- GPU\n",
    "\n",
    "![image.png](https://paullerner.github.io/aivancity_nlp/_static/colab_gpu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available(), \"Connect to GPU and try again (ask teacher for help)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGe4ha9NgfGy"
   },
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYj_37iZgjo9"
   },
   "source": [
    "Attention is a crucial component in the transformer, it allows to capture dependencies between different positions of two sequence of elements. In our case, and in most cases in NLP applications, sequences are sentences and elements are (sub)words.\n",
    "It is a powerful operation that allows to learn an alignment between each element in two sequences. It generates a score of how related each element in sequence1 and sequence2 are between each other.\n",
    "Understanding how attention works and being able to implement it are essential for anyone working with transformers. \n",
    "\n",
    "Given a query ($Q$), key ($K$), and value ($V$) tensors, the attention mechanism computes a weighted sum of the value tensor based on the similarity between the query and key tensors as shown in the following equation:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q,K,V) = \\text{softmax}\\Big(\\frac{QK^T}{\\sqrt{d_k}}\\Big)V\n",
    "$$\n",
    "\n",
    "where \n",
    "- $Q$ represents the query tensor.\n",
    "- $K$ represents the key tensor.\n",
    "- $V$ represents the value tensor.\n",
    "- $d_k$ represents the dimensionality of the key tensor.\n",
    "\n",
    "This is the image that was in the original Transformer paper and that shows the computations used in the attention.\n",
    "\n",
    "Forget about the right part, we'll get back to that later in the lab.\n",
    "\n",
    "![image](https://miro.medium.com/v2/resize:fit:1270/1*LpDpZojgoKTPBBt8wdC4nQ.png)\n",
    "\n",
    "\n",
    "In this exercise, we will dive into the attention mechanism. To do so, we are going to build a simple cross-attention function that we will then extend to a more complex multi-head self-attention module that incorporates the concept of causality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0lBpBvtiEQX"
   },
   "source": [
    "## Building a Simple Cross-Attention Function\n",
    "\n",
    "Cross-attention refers to the case where the input sequences to compute $Q$, $K$, and $V$ come from different sources. It allows models to incorporate contextual information from one sequence (S1) into another (S2). <a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1)\n",
    "\n",
    "\n",
    "Given two input sequences $S_1$ and $S_2$ and the transformation weights $W_Q$, $W_K$ and $W_V$, complete the `cross_attention` function in the cell below. \n",
    "\n",
    "You need to implement the following:\n",
    "- Calculate the query, key, and value projections using linear transformations.\n",
    "- Compute the attention scores by performing the dot product between the query and key tensors.\n",
    "- Apply softmax activation to the attention scores to obtain the attention weights.\n",
    "- Multiply the attention weights with the value tensor to get the attended values.\n",
    "- Return the attended values.\n",
    "\n",
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1) Conceptually, the self attention variant that you might have heard is the same, with the only difference that the S1 and S2 sequences are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Matrix sizes\n",
    "\n",
    "- q: query size\n",
    "- d: hidden dimension\n",
    "- c: context length\n",
    "\n",
    "\n",
    "- Q: 1xqxd\n",
    "- K, V: 1xcxd\n",
    "- Q x K:  1xqxd x 1xsxd.T \n",
    "- (QK) x V:  1xqxs  x  V  1xsxd\n",
    "\n",
    "  \n",
    "- Attn: 1xqxd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vFYCyf-GgKly"
   },
   "outputs": [],
   "source": [
    "\n",
    "def cross_attention(S1, S2, W_Q, W_K, W_V):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Source\n",
    "S1 = torch.rand((1,13,3))\n",
    "\n",
    "# Query\n",
    "S2 = torch.rand((1,4,3))\n",
    "\n",
    "# Projections\n",
    "W_Q = torch.rand((3, 2))  # Query weights\n",
    "W_K = torch.rand((3, 2))  # Key weights\n",
    "W_V = torch.rand((3, 2))  # Value weights\n",
    "\n",
    "# Perform cross-attention\n",
    "attended_values = cross_attention(S1, S2, W_Q, W_K, W_V)\n",
    "\n",
    "# Expected output # 1,4,2 (B, Sequence, Projection)\n",
    "print(f\"Output Shape: {attended_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending to Multi-Head Self-Attention\n",
    "\n",
    "### Self-Attention\n",
    "\n",
    "We will be replacing the cross-attention mechanism with self-attention. In self-attention, a single sequence acts as the query, key, and value, allowing attention to be computed within the sequence itself. This can be useful for syntactic where an attention head can model the relationship between part of speech like subjects and verbs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(S, W_Q, W_K, W_V):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([1, 13, 2])\n"
     ]
    }
   ],
   "source": [
    "# Sequence\n",
    "S = torch.rand((1,13,3))\n",
    "\n",
    "# Projections\n",
    "W_Q = torch.rand((3, 2))  # Query weights\n",
    "W_K = torch.rand((3, 2))  # Key weights\n",
    "W_V = torch.rand((3, 2))  # Value weights\n",
    "\n",
    "# Perform self-attention\n",
    "attended_values = self_attention(S, W_Q, W_K, W_V)\n",
    "\n",
    "# Expected output # 1,13, 2 (B, Sequence, Projection)\n",
    "print(f\"Output Shape: {attended_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head\n",
    "\n",
    "However, the relations present even in a single sentence are more than one. Think about number and gender agreement as one, the semantic relation between subject and object, the functional aspect that verb arguments have etc. All this cannot be modeled by a single head.\n",
    "\n",
    "For this reason, we are going to extend the single-head attention function to **multi-head attention**. In the previous implementation, we had one set of weights for the input query, resulting in a single type of _relationship between the the source and target sequence_. With multi-head attention, we can utilize _multiple parallel single-head attention modules_ to obtain diverse relationships between the query and the values. The attention operation works by projecting the sequences through a multiplication with a projection matrix, and then computing the alignment score. These are are all operation that can be parallelized since there's no interdependency between each each head. For this reasons, each head could learn to model a different linguistic intereation useful for many downstream tasks, be it syntactic, semantic or generation-based..\n",
    "\n",
    "\n",
    "As we've seen in class, this can be done simply by reshaping queries, keys and values.\n",
    "\n",
    "Project back the results using $W_O$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(S, W_Q, W_K, W_V, W_O, num_heads=4):    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([1, 13, 8])\n"
     ]
    }
   ],
   "source": [
    "# Sequence\n",
    "S = torch.rand((1,13,8))\n",
    "\n",
    "# Projections\n",
    "W_Q = torch.rand((8, 8))  # Query weights\n",
    "W_K = torch.rand((8, 8))  # Key weights\n",
    "W_V = torch.rand((8, 8))  # Value weights\n",
    "W_O = torch.rand((8, 8))  # Output proj\n",
    "\n",
    "# Perform self-attention\n",
    "attended_values = multi_head_attention(S, W_Q, W_K, W_V, W_O)\n",
    "\n",
    "# Expected output # 1, 13, 8 (B, Sequence, Projection)\n",
    "print(f\"Output Shape: {attended_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Mask\n",
    "\n",
    "GPT uses a version of self-attention called causal self-attention. When training our models for tasks like language modeling and machine translation, in practice we feed the entire train sequence to the model but, at every timestep, we want to prevent it to compute the alignment with future tokens. For this reason we use a mask that we incrementally lift at every timestep. For instance, we have a sentence that says \"Libson is a great city to live in\". At time 0, we feed the entire sentence to the model masking everything but the first token. Using the strikethrough format as masking, this will be what the model sees at step 0:\n",
    "\n",
    "- Time 0: Libson ~is a great city to live in~\n",
    "\n",
    "We then let the model generate a token a and move to step 1 where we are masking everything but the first two tokens\n",
    " \n",
    "- Time 1: Libson is ~a great city to live in~ \n",
    "\n",
    "and so on...\n",
    "\n",
    "- Time 2: Libson is a ~great city to live in~ \n",
    "- Time 3: Libson is a great ~city to live in~ \n",
    "- Time 4: Libson is a great city ~to live in~ \n",
    "- Time 5: Libson is a great city to ~live in~ \n",
    "- Time 6: Libson is a great city to live ~in~ \n",
    "\n",
    "\n",
    "![transformer](https://paullerner.github.io/aivancity_nlp/_static/attention_mask.png)\n",
    "\n",
    "Apply mask on attention using `torch.tril` and `masked_fill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_multi_head_attention(S, W_Q, W_K, W_V, W_O, num_heads=4):    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional attention:\n",
      "tensor([[[[ 7.6750,  9.8763,  7.8718],\n",
      "          [11.7096, 14.9262, 11.9657],\n",
      "          [ 8.8149, 11.3644,  9.0476]],\n",
      "\n",
      "         [[ 6.9848,  8.4330,  6.1530],\n",
      "          [ 8.9807, 10.8143,  7.9368],\n",
      "          [ 7.9229,  9.5573,  6.9868]],\n",
      "\n",
      "         [[ 8.4009, 10.4845,  9.2640],\n",
      "          [10.3813, 12.9258, 11.4504],\n",
      "          [ 8.6193, 10.7093,  9.5088]],\n",
      "\n",
      "         [[ 9.4824, 11.5997, 10.2568],\n",
      "          [13.4200, 16.4683, 14.5326],\n",
      "          [10.5152, 12.8738, 11.3774]]]])\n",
      "\n",
      "causal attention:\n",
      "tensor([[[[ 7.6750,    -inf,    -inf],\n",
      "          [11.7096, 14.9262,    -inf],\n",
      "          [ 8.8149, 11.3644,  9.0476]],\n",
      "\n",
      "         [[ 6.9848,    -inf,    -inf],\n",
      "          [ 8.9807, 10.8143,    -inf],\n",
      "          [ 7.9229,  9.5573,  6.9868]],\n",
      "\n",
      "         [[ 8.4009,    -inf,    -inf],\n",
      "          [10.3813, 12.9258,    -inf],\n",
      "          [ 8.6193, 10.7093,  9.5088]],\n",
      "\n",
      "         [[ 9.4824,    -inf,    -inf],\n",
      "          [13.4200, 16.4683,    -inf],\n",
      "          [10.5152, 12.8738, 11.3774]]]])\n",
      "Output Shape: torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# Sequence\n",
    "S = torch.rand((1,3,8))\n",
    "\n",
    "# Projections\n",
    "W_Q = torch.rand((8, 8))  # Query weights\n",
    "W_K = torch.rand((8, 8))  # Key weights\n",
    "W_V = torch.rand((8, 8))  # Value weights\n",
    "W_O = torch.rand((8, 8))  # Output proj\n",
    "\n",
    "# Perform self-attention\n",
    "attended_values = causal_multi_head_attention(S, W_Q, W_K, W_V, W_O)\n",
    "\n",
    "# Expected output # 1, 3, 8 (B, Sequence, Projection)\n",
    "print(f\"Output Shape: {attended_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can now look back at the attention figure from the paper. Hopefully, you are now able to understand also the right side of the figure.\n",
    "\n",
    "![image](https://miro.medium.com/v2/resize:fit:1270/1*LpDpZojgoKTPBBt8wdC4nQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs7ar9XJu0u6"
   },
   "source": [
    "### Pytorch Module\n",
    "\n",
    "The last modification involves embedding our function into a PyTorch module. As you may have noticed, in the previous exercise, we passed the transformation weights as inputs to the function. In a real-world scenario, these matrices are learned, and PyTorch can keep track of them for us.\n",
    "\n",
    "- Complete the missing lines on the initialization of the module and the forward pass.\n",
    "- add dropout on the attention weights and the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size=8, num_heads=2, dropout=0.1, seq_len=3):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_module = CausalSelfAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# Sequence\n",
    "S = torch.rand((1,3,8))\n",
    "\n",
    "# Perform self-attention\n",
    "attended_values = attention_module(S)\n",
    "\n",
    "# Expected output # 1, 3, 8 (B, Sequence, Projection)\n",
    "print(f\"Output Shape: {attended_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "![transformer](https://paullerner.github.io/aivancity_nlp/_static/transformer_decoder.png)\n",
    "\n",
    "## Attention is almost all you need: feedforward neural network\n",
    "\n",
    "Simple Neural network of two layers with a ReLU activation in-between and dropout at output. The intermediate dimension should be 4 times `hidden_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Block\n",
    "\n",
    "- stack CausalSelfAttention and FeedForward\n",
    "- add residual connections\n",
    "- add layer norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, hidden_size=8, num_heads=2, dropout=0.1, seq_len=3):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence\n",
    "S = torch.rand((1,3,8))\n",
    "\n",
    "block = Block()\n",
    "# Perform self-attention\n",
    "output = block(S)\n",
    "\n",
    "# Expected output # 1, 3, 8 (B, Sequence, Projection)\n",
    "print(f\"Output Shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Transformer\n",
    "- word embeddings\n",
    "- position embeddings\n",
    "- as many blocks as you like to stack\n",
    "- output layer back to the vocabulary (no need for softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size=100, hidden_size=8, num_heads=2, dropout=0.1, seq_len=3, num_layers=2):\n",
    "        super().__init__()        \n",
    "            \n",
    "    def forward(self, input_ids):\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.randint(0,100,(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[85, 10,  4]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = transformer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 100])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores (not probabilities because not normalized) over the complete vocabulary, for each token in the sentence\n",
    "# shape: batch size, seq_len, V\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRiFro12JhO3"
   },
   "source": [
    "# Training\n",
    "\n",
    "A peak into Language Modeling (next class)\n",
    "\n",
    "\n",
    "![lm](https://paullerner.github.io/aivancity_nlp/_static/lm.png)\n",
    "\n",
    "A language model estimates the probability of a sequence of words $w$:\n",
    "$$P(w)=\\prod_t^{|w|} P(w_t | w_{<t}) = P(w_1)  P(w_2|w_1)  P(w_3 | w_1 w_2)...$$\n",
    "\n",
    "See how this turns into a sequence of classification problem:\n",
    "- first $P(w_1)$\n",
    "- then $P(w_2|w_1)$\n",
    "- etc.\n",
    "\n",
    "The model \"predicts the next word\" given a context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/matos/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "texts = load_dataset('wikitext', 'wikitext-103-raw-v1')['train'].shuffle(seed=1111).select(range(10000))[\"text\"]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Following the death of Finan , bishop of Lindisfarne , Alhfrith of Deira , in collusion with Wilfred of York , Agilbert of Wessex and others , were determined to persuade Oswiu to rule in favour of the Roman rite of Christianity within the kingdoms over which he had imperium . The case was debated in Oswiu 's presence at the Synod of Whitby in 664 , with Colmán , Hild and Cedd defending the Celtic rite and the tradition inherited from Aidan , and Wilifred speaking for the Roman position . The Roman cause prevailed and the former division of ecclesiastical authorities was set aside . Those who could not accept it , including Colmán , departed elsewhere . \\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenization\n",
    "\n",
    "We almost did not talk about tokenization yet! We've assumed words, which is impractical given finite vocabulary size.\n",
    "\n",
    "Instead, LLMs rely on BPE, a data compression technique, which segments rare words into subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/matos/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "seq_len=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ĠFollowing', 'Ġthe', 'Ġdeath', 'Ġof', 'ĠFin', 'an', 'Ġ,', 'Ġbishop', 'Ġof', 'ĠLind', 'isf', 'ar', 'ne', 'Ġ,', 'ĠAl', 'h', 'fr', 'ith', 'Ġof', 'ĠDe', 'ira', 'Ġ,', 'Ġin', 'Ġcollusion', 'Ġwith', 'ĠWil', 'fred', 'Ġof', 'ĠYork', 'Ġ,', 'ĠAg', 'il', 'bert', 'Ġof', 'ĠWes', 'sex', 'Ġand', 'Ġothers', 'Ġ,', 'Ġwere', 'Ġdetermined', 'Ġto', 'Ġpersuade', 'ĠOsw', 'iu', 'Ġto', 'Ġrule', 'Ġin', 'Ġfavour', 'Ġof', 'Ġthe', 'ĠRoman', 'Ġrite', 'Ġof', 'ĠChristianity', 'Ġwithin', 'Ġthe', 'Ġkingdoms', 'Ġover', 'Ġwhich', 'Ġhe', 'Ġhad', 'Ġimper', 'ium', 'Ġ.', 'ĠThe', 'Ġcase', 'Ġwas', 'Ġdebated', 'Ġin', 'ĠOsw', 'iu', \"Ġ'\", 's', 'Ġpresence', 'Ġat', 'Ġthe', 'ĠSyn', 'od', 'Ġof', 'ĠWhit', 'by', 'Ġin', 'Ġ6', '64', 'Ġ,', 'Ġwith', 'ĠCol', 'm', 'Ã¡n', 'Ġ,', 'ĠH', 'ild', 'Ġand', 'ĠC', 'edd', 'Ġdefending', 'Ġthe', 'ĠCeltic', 'Ġrite', 'Ġand', 'Ġthe', 'Ġtradition', 'Ġinherited', 'Ġfrom', 'ĠAid', 'an', 'Ġ,', 'Ġand', 'ĠWil', 'if', 'red', 'Ġspeaking', 'Ġfor', 'Ġthe', 'ĠRoman', 'Ġposition', 'Ġ.', 'ĠThe', 'ĠRoman', 'Ġcause', 'Ġprevailed', 'Ġand', 'Ġthe', 'Ġformer', 'Ġdivision', 'Ġof', 'Ġecc', 'lesiastical', 'Ġauthorities', 'Ġwas', 'Ġset', 'Ġaside', 'Ġ.', 'ĠThose', 'Ġwho', 'Ġcould', 'Ġnot', 'Ġaccept', 'Ġit', 'Ġ,', 'Ġincluding', 'ĠCol', 'm', 'Ã¡n', 'Ġ,', 'Ġdeparted', 'Ġelsewhere', 'Ġ.', 'Ġ', 'Ċ']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch = texts[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "huggingface's `transformers` provides a convenient way to tokenize text, it also takes care of padding the text so that we can wrap all examples of a batch in the same `Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True, max_length=seq_len)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14207,   262,  1918,   286,  4463,   272,   837, 24233,   286,  9329,\n",
       "          4468,   283,   710,   837,   978,    71,  8310,   342,   286,  1024,\n",
       "          8704,   837,   287, 29771,   351,  5187, 39193,   286,  1971,   837,\n",
       "          2449,   346,  4835,   286, 18622,  8044,   290,  1854,   837,   547,\n",
       "          5295,   284, 20999, 30317, 16115,   284,  3896,   287,  7075,   286,\n",
       "           262,  7993, 46048,   286, 13624,  1626,   262, 41901,   625,   543,\n",
       "           339,   550, 11071,  1505,   764,   383,  1339,   373, 24594,   287,\n",
       "         30317, 16115,   705,    82,  4931,   379,   262, 16065,   375,   286,\n",
       "         13183,  1525,   287,   718,  2414,   837,   351,  1623,    76, 21162,\n",
       "           837,   367,   688,   290,   327,  6048, 11749,   262, 27986, 46048,\n",
       "           290,   262,  6761, 19552,   422, 22225,   272,   837,   290,  5187,\n",
       "           361,   445,  5486,   329,   262,  7993,  2292,   764,   383,  7993,\n",
       "          2728, 34429,   290,   262,  1966,  7297,   286, 21399],\n",
       "        [  796,   796, 15417,   796,   796,   220,   198, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [  383, 17119, 35622,   284, 13583, 27928,   810,   837,  1864,   284,\n",
       "           530,  4039,   705,    82,  1848,   837,   262, 17119, 16675, 40280,\n",
       "         46265,   265,  6909,   290,  5371,   683,   286, 37268,   780,   286,\n",
       "           262,   867,  7040,   837,   543,   465, 10377,   547,  4385,   284,\n",
       "           423, 13351,   764,   679, 13772,   465,  3656,   329,   748,   721,\n",
       "          8821,   465,  5536,  9007,   290,  4438,   284,  3350,   257,   649,\n",
       "          4822,   290, 11189,   326, 17119,  4219,   257,  1218,  1368,   837,\n",
       "           475,   484,  6520,   764,   220,   198, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the padding: small texts are padded by `tokenizer.eos_token_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(vocab_size=tokenizer.vocab_size, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 50257])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as before (only larger seq_len and V)\n",
    "logits = transformer(input_ids)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-supervision\n",
    "\n",
    "Remember the greatest thing about Language Modeling: we don't need to annotate data!\n",
    "\n",
    "The model should predict the next word given the context so we just need to shift the input by 1 to get the labels!\n",
    "\n",
    "Compute the loss on one batch using `nn.CrossEntropyLoss`. Be careful about the padding! We don't want our model to learn to predict padding at the end of text!\n",
    "\n",
    "Like in the previous Practical Work, remember to flatten the batch dimension with the sequence dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.0828, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss of randomly initialized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice anything about this value? What about its exponentiate? Ever heard of perplexity? More about this in the next class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "Ensure that everything is on GPU by calling `.cuda()` or passing `device=\"cuda\"` on init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(vocab_size=tokenizer.vocab_size, hidden_size=128, num_layers=6, num_heads=4, dropout=0.1, seq_len=seq_len).cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=0.0001)\n",
    "\n",
    "batch_size = 32\n",
    "# in the interest of time, we simply overfit on a single batch\n",
    "# try to train on the complete texts when you have more time\n",
    "loader = torch.utils.data.DataLoader(texts[:batch_size], batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "losses = []\n",
    "step = 0\n",
    "for epoch in range(1000):\n",
    "    for text_batch in loader:\n",
    "        input_ids = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True, max_length=seq_len)['input_ids'].cuda()\n",
    "        logits = transformer(input_ids)\n",
    "        raise NotImplementedError(\"TODO compute loss\")\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()        \n",
    "        nn.utils.clip_grad_norm_(transformer.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        if step % 20 == 0:\n",
    "            print(epoch, step, losses[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7c41adaf1120>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), \"transformer.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(model, input_ids, max_new_tokens=32):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        # get the predictions\n",
    "        logits = model(input_ids)\n",
    "        # focus only on the last time step\n",
    "        logits = logits[:, -1] # becomes (B, C)\n",
    "        # greedy decoding\n",
    "        idx_next = logits.argmax(1).unsqueeze(0)\n",
    "        # append sampled index to the running sequence\n",
    "        input_ids = torch.cat((input_ids, idx_next), dim=1) # (B, T+1)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load previously saved model\n",
    "#transformer.load_state_dict(torch.load(\"transformer.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Following the death of Finan , bishop of Lindisfarne , Alhfrith of Deira , in collusion with Wilfred of York , Agilbert of Wessex and others , were determined to persuade Oswiu to rule in favour of the Roman rite of Christianity within the kingdoms over which he had imperium . The case was debated in Oswiu 's presence at the Synod of Whitby in 664 , with Colmán , Hild and Cedd defending the Celtic rite and the tradition inherited from Aidan , and Wilifred speaking for the Roman position . The Roman cause prevailed and the former division of ecclesiastical authorities was set aside . Those who could not accept it , including Colmán , departed elsewhere . \\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When overfitting on one single batch, the model simply memorizes training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \" Following\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Following the death of Finan, bishop of Lindisfarne, Alhfrith of Deira, in collusion with Wilfred of York, Agilbert']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer([prompt], return_tensors='pt', padding=True, truncation=True, max_length=seq_len)['input_ids'].cuda()\n",
    "output = greedy(transformer, input_ids)\n",
    "\n",
    "tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets a bit better when you train on the 10,000 examples for 20,000 steps, but that roughly takes one hour on a labtop GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Following his home of Work Records, Shawn Conductwings days on January 2013 and Valan and 17 August 18 & 200, 1990. \\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" The first first known for the United States, Texas Texas, was announced by a member of 1829 and the United States's Championship. In February 2007, the\"]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \" The\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Visualize Attentions\n",
    "\n",
    "Now that we understand the basic mechanisms of attention, we can check the activated attention patterns in a pretrained BERT model (Devlin et al. 2018). Recall that BERT is an encoder-based transformer model which is based on a stack of self-attention blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uI-bIuxUteuC",
    "outputId": "40ee1d8b-a37f-4c58-dbcb-6835d83c298a"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from bertviz import head_view\n",
    "\n",
    "# Define a sample input text\n",
    "text = \"I will go for a run and will jump into a lake.\"\n",
    "\n",
    "# Instantiate the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "# Convert tokens to token IDs\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# Create attention mask\n",
    "attention_mask = [1] * len(token_ids)\n",
    "\n",
    "# Convert token IDs and attention mask to tensors\n",
    "input_ids = torch.tensor([token_ids])\n",
    "attention_mask = torch.tensor([attention_mask])\n",
    "\n",
    "# Generate the transformer output\n",
    "outputs = model(input_ids, attention_mask=attention_mask, output_attentions=True)\n",
    "\n",
    "# Extract attentions and check the shape\n",
    "outputs.attentions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we extracted an attention from the first layer. The first dimension is the bach, the second one is the number of heads used in the first layer, and the last two dimensions are the sequence length. Given that this was a self attention block the last two numbers are equal.\n",
    "\n",
    "We can now use a method from the [bertviz library](https://github.com/jessevig/bertviz) and plot all the heads.\n",
    "\n",
    "You'll see a dropdown menu that allows you the select a layer of the model (GPT-2 has 12). You'll then see a color for every head used in that layer (GPT-2 has 12 head per layer). By default all heads are shown, click on a color to activate/disactivate that head. It can help starting by activating only one head and checking the learned relation learn by that self attentino head. By hovering over each word you can see the attention weigths that linked that words to all the others.\n",
    "\n",
    "**Question** Do you notice any interesting (linguistic) pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(outputs.attentions, tokens=tokens)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GAQAv4iil7LX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "004553b714df4f9fa94e3e8aad429cb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "00d8c994da6041949554985cc8425e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06bae1d9afcb42f79e8c9447f34568df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b49db4be6db4ca0aca576d90796e498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10dd6e3f02dd4661abfaaf75b43e2914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c46a02021334c9dafa7e3cbea7c3fd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ec5a1f535934e2ba6c4f67357ab97b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "208fa2e9acc8443698cf6f1cd0f7bf82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2584967c2b7b4821a8aa1ae1eaa602b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdfb7a69f3524fd3a66de434c0e03ecc",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_63e549e71a2b425dba863727737f53bb",
      "value": 570
     }
    },
    "30aba7c8bea241efb630266330eaec29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ec5a1f535934e2ba6c4f67357ab97b4",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50f169d401e348b486e15a68b9f0bebf",
      "value": 231508
     }
    },
    "3c28f8163719481ba3d4cc34cb055060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56e04d73c266491ebe0623f69f9ce763",
      "placeholder": "​",
      "style": "IPY_MODEL_208fa2e9acc8443698cf6f1cd0f7bf82",
      "value": " 440M/440M [00:04&lt;00:00, 103MB/s]"
     }
    },
    "411c6dab66b54654a0405f4df08c5639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de646d633a914d9592090f65051a62ff",
      "placeholder": "​",
      "style": "IPY_MODEL_00d8c994da6041949554985cc8425e8e",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "481efe6d7c3a46d08a37619d8cd5809b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "484405deb40f462f81e82e6139d77fd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd02d3c7f1b54926be6f7599455fb024",
      "placeholder": "​",
      "style": "IPY_MODEL_0b49db4be6db4ca0aca576d90796e498",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "50f169d401e348b486e15a68b9f0bebf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "56e04d73c266491ebe0623f69f9ce763": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63e549e71a2b425dba863727737f53bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "652d57b1fcc6438c993c8ef6fc0a14fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70381041f4544b04bb3bb9e49c8defc5",
      "placeholder": "​",
      "style": "IPY_MODEL_10dd6e3f02dd4661abfaaf75b43e2914",
      "value": " 28.0/28.0 [00:00&lt;00:00, 276B/s]"
     }
    },
    "67aef5b516a54f73bd18947635221ce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_686bbfa0b07e449f84da2d23328aed52",
      "placeholder": "​",
      "style": "IPY_MODEL_8fa6940c2a1047f2a364bff4abc0776e",
      "value": " 570/570 [00:00&lt;00:00, 8.40kB/s]"
     }
    },
    "686bbfa0b07e449f84da2d23328aed52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69384a586dfb4bdcbe22ab9d66443ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70381041f4544b04bb3bb9e49c8defc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77e4148a5eff405a93f81cdf131daf3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a198c7be8974598a61e2f231502e2f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b983da7cd8f24ee4a3e2ee378c8e8d3b",
       "IPY_MODEL_cd2c2b9d0e2a4144970196a470ff6437",
       "IPY_MODEL_3c28f8163719481ba3d4cc34cb055060"
      ],
      "layout": "IPY_MODEL_004553b714df4f9fa94e3e8aad429cb4"
     }
    },
    "8fa6940c2a1047f2a364bff4abc0776e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac296dbdef4d40d38e7fdec2ebcd5382": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8bf52de9eae4860bd5c8a3c6d6e4bb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b983da7cd8f24ee4a3e2ee378c8e8d3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77e4148a5eff405a93f81cdf131daf3b",
      "placeholder": "​",
      "style": "IPY_MODEL_69384a586dfb4bdcbe22ab9d66443ab5",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "cd2c2b9d0e2a4144970196a470ff6437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_481efe6d7c3a46d08a37619d8cd5809b",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1130befba034636a0173fec87a18a92",
      "value": 440449768
     }
    },
    "cdfb7a69f3524fd3a66de434c0e03ecc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0a6f5622ecb4ef4a38c1ce90f15c072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d6381879001341a18187c6e63f10c464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d962809a60f64f8b9097a98fce3ea48d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd02d3c7f1b54926be6f7599455fb024": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de646d633a914d9592090f65051a62ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1130befba034636a0173fec87a18a92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e5f17745469147cd9233eeb8b5b8461d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_484405deb40f462f81e82e6139d77fd6",
       "IPY_MODEL_fad47dcd32844881bb2b07606c54cd6d",
       "IPY_MODEL_652d57b1fcc6438c993c8ef6fc0a14fd"
      ],
      "layout": "IPY_MODEL_06bae1d9afcb42f79e8c9447f34568df"
     }
    },
    "e6e49d02bd8042648d91a81c1e7b06f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e728ccc9ef7a4ad78d2d64308495c322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6e49d02bd8042648d91a81c1e7b06f2",
      "placeholder": "​",
      "style": "IPY_MODEL_d6381879001341a18187c6e63f10c464",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "eb7badb8586b466c9ea01d163c45e820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eba9114e27f54e7f9f5926971e83de2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e728ccc9ef7a4ad78d2d64308495c322",
       "IPY_MODEL_30aba7c8bea241efb630266330eaec29",
       "IPY_MODEL_ecf82a9385c74c57811a5390693b475c"
      ],
      "layout": "IPY_MODEL_eb7badb8586b466c9ea01d163c45e820"
     }
    },
    "ecf82a9385c74c57811a5390693b475c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac296dbdef4d40d38e7fdec2ebcd5382",
      "placeholder": "​",
      "style": "IPY_MODEL_d962809a60f64f8b9097a98fce3ea48d",
      "value": " 232k/232k [00:00&lt;00:00, 1.89MB/s]"
     }
    },
    "f3e49e667464406cbd7a283c5dc6c354": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_411c6dab66b54654a0405f4df08c5639",
       "IPY_MODEL_2584967c2b7b4821a8aa1ae1eaa602b6",
       "IPY_MODEL_67aef5b516a54f73bd18947635221ce3"
      ],
      "layout": "IPY_MODEL_b8bf52de9eae4860bd5c8a3c6d6e4bb6"
     }
    },
    "fad47dcd32844881bb2b07606c54cd6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c46a02021334c9dafa7e3cbea7c3fd9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0a6f5622ecb4ef4a38c1ce90f15c072",
      "value": 28
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
